{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb44827-a885-4e93-8517-94e4244f6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import os\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "manual_seed = 23\n",
    "\n",
    "np.random.seed(manual_seed)\n",
    "pl.set_random_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77631e4-08f3-41df-914f-73dcdfb0bb1a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79252084-e705-4fe0-ab67-cf8213cccc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/500k_50k'\n",
    "\n",
    "df_train = pl.read_parquet(filename + '_train.parquet')\n",
    "df_dev = pl.read_parquet(filename + '_dev.parquet')\n",
    "df_test = pl.read_parquet(filename + '_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b46c575-30ac-487d-89c8-3e4647bb508b",
   "metadata": {},
   "source": [
    "## Downsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d03d4-8460-4af4-b17c-7ac89ed36b34",
   "metadata": {},
   "source": [
    "The obtained dataset contains ~45M reviews. Training on this amount would take too long, so I decided to train models on smaller chunks of data. I aimed at something that wouldn't take more than 6 hours of training. For Roberta, this meant training on 500k randomly selected reviews. I decided to evaluate data on 50k reviews, which means 10% of the size of the training data. While the amount of training data might change, this evaluation set will be used for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d69c034-40d8-42dc-aab9-fddb62650a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(5000, seed=manual_seed, shuffle=True)\n",
    "df_dev = df_dev.sample(500, seed=manual_seed, shuffle=True)\n",
    "df_test = df_test.sample(500, seed=manual_seed, shuffle=True)\n",
    "\n",
    "# TODO DELETE THIS BECAUSE PREPROCESSING!\n",
    "#df_train = df_train.cast({'recommended': pl.Int8})\n",
    "#df_dev = df_dev.cast({'recommended': pl.Int8})\n",
    "#df_test = df_test.cast({'recommended': pl.Int8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088cead-20f2-4e23-974c-4408c3491c14",
   "metadata": {},
   "source": [
    "## Selecting relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093adb68-5bbe-444f-bb7d-180762d63cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended\n",
    "# df_train = df_train.select(['review_text', 'recommended']).rename({'review_text': 'text', 'recommended': 'label'})\n",
    "# df_dev = df_dev.select(['review_text', 'recommended']).rename({'review_text': 'text', 'recommended': 'label'})\n",
    "# df_test = df_test.select(['review_text', 'recommended']).rename({'review_text': 'text', 'recommended': 'label'})\n",
    "\n",
    "# found_helpful\n",
    "df_train = df_train.select(['review_text', 'found_helpful']).rename({'review_text': 'text', 'found_helpful': 'label'})\n",
    "df_dev = df_dev.select(['review_text', 'found_helpful']).rename({'review_text': 'text', 'found_helpful': 'label'})\n",
    "df_test = df_test.select(['review_text', 'found_helpful']).rename({'review_text': 'text', 'found_helpful': 'label'})\n",
    "\n",
    "# found funny\n",
    "# df_train = df_train.select(['review_text', 'found_funny']).rename({'review_text': 'text', 'found_funny': 'label'})\n",
    "# df_dev = df_dev.select(['review_text', 'found_funny']).rename({'review_text': 'text', 'found_funny': 'label'})\n",
    "# df_test = df_test.select(['review_text', 'found_funny']).rename({'review_text': 'text', 'found_funny': 'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9706b26-1105-469e-8311-1b92f9d47913",
   "metadata": {},
   "source": [
    "## Create dataset for transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f13b30-249f-4421-9ea9-4dfc51f7f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': Dataset(df_train.to_arrow()),\n",
    "    'dev': Dataset(df_dev.to_arrow()),\n",
    "    'test': Dataset(df_test.to_arrow())\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850681a-2cce-495d-9d72-261dd7609ec6",
   "metadata": {},
   "source": [
    "# Evaluating - transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b5011b-e1f0-41ea-82fb-4e9a24396a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62fec6b-b1dc-46a2-bb7b-8f89bb6d914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations distilbert\n",
    "model_name = 'models/steam-classification-distilbert500k/checkpoint-15625'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8624423d-238f-45aa-a809-e9dabff5597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/steam-classification-distilbert500k-funny/checkpoint-14067'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14894442-9cb5-428c-9a6a-a38c723fc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/steam-classification-distilbert500k-funny2/checkpoint-15625'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce1cec-b14d-413d-8f21-f74490b42a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'models/steam-classification-distilbert500k-funny3/checkpoint-15625'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7762ea8f-a0aa-4536-b173-fe61a1490a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations roberta\n",
    "model_name = 'models/steam-classification-roberta500k/checkpoint-31250'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ff78771-2df7-4680-bc62-73e8c2d32a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations distilbert\n",
    "model_type = 'roberta-large'\n",
    "model_name = 'FacebookAI/roberta-large'\n",
    "output_dir='models/steam-classification-roberta500k'\n",
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "lr = 5e-5 # default\n",
    "weight_decay = 0\n",
    "eval_steps=0.1 # eval after 10% is done\n",
    "save_steps=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a244143-77d9-4ba1-98f5-eeacc80a8a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    text = examples[\"text\"]\n",
    "    # it is possible to return tensors in pytorch, but then you need to pad everything which is inconvenient because it is better to do in collator\n",
    "    return tokenizer(text, truncation=True, return_tensors=\"np\", max_length=128)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d98950-cf5b-4736-9f47-89f167f784ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dc6c40aaeb4c7a8ae6ef5fe4f61101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf896ea851cd4efc8c1a6def7a34950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d5c0c22e2948a5bcf5c72d89612a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66cdf03-be6c-40e4-8e4d-3b1e77e77a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}\n",
    "    # return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e3aa081-b548-4500-9b24-1df8553a7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy import stats\n",
    "\n",
    "spearmanr_func = lambda x, y: stats.spearmanr(x, y)[0]\n",
    "pearsonr_func = lambda x, y: stats.pearsonr(x, y)[0]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    #spearmanr = spearmanr_func(predictions, labels)\n",
    "    #pearsonr = pearsonr_func(predictions, labels)\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2} #, \"spearmanr\": spearmanr, \"pearsonr\": pearsonr}\n",
    "\n",
    "def compute_metrics_check(predictions, labels):\n",
    "    #spearmanr = spearmanr_func(predictions, labels)\n",
    "    #pearsonr = pearsonr_func(predictions, labels)\n",
    "    # labels = labels.reshape(-1, 1)\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2} #, \"spearmanr\": spearmanr, \"pearsonr\": pearsonr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6fd13e45-8880-45cf-bfc8-a32ac6ba17ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "# DISTILBert\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=tokenized_dataset['dev'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset=tokenized_dataset['dev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e532a5e0-445e-4a20-b1f3-c469333fb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev.with_columns(\n",
    "    pl.lit(predictions.reshape(-1)).alias('funny')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df2f748d-db5f-4398-a606-0bfb40dd6ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n"
     ]
    }
   ],
   "source": [
    "df_dev = df_dev.with_columns(\n",
    "    pl.lit(predictions.reshape(-1)).alias('funny2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b593d6f5-fdd4-4329-9180-02dad8164729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = df_dev.with_columns(\n",
    "    pl.lit(np.zeros(len(label_ids))).alias('zeros')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15a00ed8-3b42-47e3-a419-0a808e47cdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0024860459868941793, 'mae': 0.006757692098994974, 'r2': 0.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics_check(df_dev['label'], df_dev['zeros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "faff54c6-2e8d-4b9f-a0a4-6ab4bed9f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0023629834534891593,\n",
       " 'mae': 0.011589905637799375,\n",
       " 'r2': -23.61761824304716}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics_check(df_dev['label'], df_dev['funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea70efed-0369-4952-967a-da30e66e5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.0024860459868941793, 'mae': 0.006757692098994974, 'r2': 0.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics_check(df_dev['label'], df_dev['zeros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f22bd3fd-8d5a-4b3f-a8e7-8e6564e11e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse': 0.007468927305274942,\n",
       " 'mae': 0.062205897909022,\n",
       " 'r2': -1.7133070431903619}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: run x2vzpsr5 was previously created and deleted; try a new run name (<Response [409]>)\n"
     ]
    }
   ],
   "source": [
    "compute_metrics_check(df_dev['label'], df_dev['funny2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "78897e30-867b-4473-9598-36e6b5503a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x713bcb7e8be0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 713ba7f26f80, raw_cell=\"df_dev.sort('funny2', descending=True)[400:420]\" store_history=True silent=False shell_futures=True cell_id=78897e30-867b-4473-9598-36e6b5503a78>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:441\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:732\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:363\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    362\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>label</th><th>funny</th><th>zeros</th><th>funny2</th></tr><tr><td>str</td><td>f64</td><td>f32</td><td>f64</td><td>f32</td></tr></thead><tbody><tr><td>&quot;Feels like 1998, being thirtee…</td><td>0.0</td><td>0.043372</td><td>0.0</td><td>0.245534</td></tr><tr><td>&quot;Supermarket Simulator, the lat…</td><td>0.0</td><td>0.04319</td><td>0.0</td><td>0.245361</td></tr><tr><td>&quot;I am not paying AU$1600+ to ex…</td><td>0.0</td><td>0.040488</td><td>0.0</td><td>0.245341</td></tr><tr><td>&quot;So I had a huge wall of text t…</td><td>0.0</td><td>0.083059</td><td>0.0</td><td>0.245128</td></tr><tr><td>&quot;[Intro: Travis Scott]\n",
       "Yeah\n",
       "Yea…</td><td>0.0</td><td>0.055211</td><td>0.0</td><td>0.244843</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;♥♥♥♥♥ i just be playing lego g…</td><td>0.0</td><td>0.01494</td><td>0.0</td><td>0.244061</td></tr><tr><td>&quot;Pushed a man off motherbase in…</td><td>0.0</td><td>0.033119</td><td>0.0</td><td>0.244056</td></tr><tr><td>&quot;⠀⠘⡀⠀⠀⠀⠀people who play ⠀⠀⠀⠀⠀ ⠀…</td><td>0.011765</td><td>0.065314</td><td>0.0</td><td>0.243906</td></tr><tr><td>&quot;: Yakuza 0 is a dense game and…</td><td>0.011765</td><td>0.063706</td><td>0.0</td><td>0.243862</td></tr><tr><td>&quot;You&#x27;re going to let me play 85…</td><td>0.0</td><td>0.042222</td><td>0.0</td><td>0.243805</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 5)\n",
       "┌─────────────────────────────────┬──────────┬──────────┬───────┬──────────┐\n",
       "│ text                            ┆ label    ┆ funny    ┆ zeros ┆ funny2   │\n",
       "│ ---                             ┆ ---      ┆ ---      ┆ ---   ┆ ---      │\n",
       "│ str                             ┆ f64      ┆ f32      ┆ f64   ┆ f32      │\n",
       "╞═════════════════════════════════╪══════════╪══════════╪═══════╪══════════╡\n",
       "│ Feels like 1998, being thirtee… ┆ 0.0      ┆ 0.043372 ┆ 0.0   ┆ 0.245534 │\n",
       "│ Supermarket Simulator, the lat… ┆ 0.0      ┆ 0.04319  ┆ 0.0   ┆ 0.245361 │\n",
       "│ I am not paying AU$1600+ to ex… ┆ 0.0      ┆ 0.040488 ┆ 0.0   ┆ 0.245341 │\n",
       "│ So I had a huge wall of text t… ┆ 0.0      ┆ 0.083059 ┆ 0.0   ┆ 0.245128 │\n",
       "│ [Intro: Travis Scott]           ┆ 0.0      ┆ 0.055211 ┆ 0.0   ┆ 0.244843 │\n",
       "│ Yeah                            ┆          ┆          ┆       ┆          │\n",
       "│ Yea…                            ┆          ┆          ┆       ┆          │\n",
       "│ …                               ┆ …        ┆ …        ┆ …     ┆ …        │\n",
       "│ ♥♥♥♥♥ i just be playing lego g… ┆ 0.0      ┆ 0.01494  ┆ 0.0   ┆ 0.244061 │\n",
       "│ Pushed a man off motherbase in… ┆ 0.0      ┆ 0.033119 ┆ 0.0   ┆ 0.244056 │\n",
       "│ ⠀⠘⡀⠀⠀⠀⠀people who play ⠀⠀⠀⠀⠀ ⠀… ┆ 0.011765 ┆ 0.065314 ┆ 0.0   ┆ 0.243906 │\n",
       "│ : Yakuza 0 is a dense game and… ┆ 0.011765 ┆ 0.063706 ┆ 0.0   ┆ 0.243862 │\n",
       "│ You're going to let me play 85… ┆ 0.0      ┆ 0.042222 ┆ 0.0   ┆ 0.243805 │\n",
       "└─────────────────────────────────┴──────────┴──────────┴───────┴──────────┘"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x713bcb7e8be0>> (for post_run_cell), with arguments args (<ExecutionResult object at 713ba7f27130, execution_count=85 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 713ba7f26f80, raw_cell=\"df_dev.sort('funny2', descending=True)[400:420]\" store_history=True silent=False shell_futures=True cell_id=78897e30-867b-4473-9598-36e6b5503a78> result=shape: (20, 5)\n",
      "┌─────────────────────────────────┬──────────┬──────────┬───────┬──────────┐\n",
      "│ text                            ┆ label    ┆ funny    ┆ zeros ┆ funny2   │\n",
      "│ ---                             ┆ ---      ┆ ---      ┆ ---   ┆ ---      │\n",
      "│ str                             ┆ f64      ┆ f32      ┆ f64   ┆ f32      │\n",
      "╞═════════════════════════════════╪══════════╪══════════╪═══════╪══════════╡\n",
      "│ Feels like 1998, being thirtee… ┆ 0.0      ┆ 0.043372 ┆ 0.0   ┆ 0.245534 │\n",
      "│ Supermarket Simulator, the lat… ┆ 0.0      ┆ 0.04319  ┆ 0.0   ┆ 0.245361 │\n",
      "│ I am not paying AU$1600+ to ex… ┆ 0.0      ┆ 0.040488 ┆ 0.0   ┆ 0.245341 │\n",
      "│ So I had a huge wall of text t… ┆ 0.0      ┆ 0.083059 ┆ 0.0   ┆ 0.245128 │\n",
      "│ [Intro: Travis Scott]           ┆ 0.0      ┆ 0.055211 ┆ 0.0   ┆ 0.244843 │\n",
      "│ Yeah                            ┆          ┆          ┆       ┆          │\n",
      "│ Yea…                            ┆          ┆          ┆       ┆          │\n",
      "│ …                               ┆ …        ┆ …        ┆ …     ┆ …        │\n",
      "│ ♥♥♥♥♥ i just be playing lego g… ┆ 0.0      ┆ 0.01494  ┆ 0.0   ┆ 0.244061 │\n",
      "│ Pushed a man off motherbase in… ┆ 0.0      ┆ 0.033119 ┆ 0.0   ┆ 0.244056 │\n",
      "│ ⠀⠘⡀⠀⠀⠀⠀people who play ⠀⠀⠀⠀⠀ ⠀… ┆ 0.011765 ┆ 0.065314 ┆ 0.0   ┆ 0.243906 │\n",
      "│ : Yakuza 0 is a dense game and… ┆ 0.011765 ┆ 0.063706 ┆ 0.0   ┆ 0.243862 │\n",
      "│ You're going to let me play 85… ┆ 0.0      ┆ 0.042222 ┆ 0.0   ┆ 0.243805 │\n",
      "└─────────────────────────────────┴──────────┴──────────┴───────┴──────────┘>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:436\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:724\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    723\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 724\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:359\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "df_dev.sort('funny2', descending=True)[400:420]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "419ff3db-d790-4adb-88b6-54e7a9ab47bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My gambling addict friend said if I post a review and it gets 75 likes and 20 Awards that he will buy me a case of beer and some vodka, so I'm just gonna leave this here.\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "df_dev.sort('funny', descending=True)['text'][47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34233af2-0c41-4d45-b64d-84c9c7c29b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02588235, 0.        , 0.01176471, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a799d793-b869-4ae6-a872-35161da747bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02588235, 0.        , 0.01176471, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaf201a1-782c-442b-a8b2-b8276b653395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5369579792022705,\n",
       " 'eval_model_preparation_time': 0.0054,\n",
       " 'eval_accuracy': 0.836,\n",
       " 'eval_runtime': 6.1489,\n",
       " 'eval_samples_per_second': 81.315,\n",
       " 'eval_steps_per_second': 10.246}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roberta\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    eval_dataset=tokenized_dataset['dev'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea9ddb-b9c4-41b0-bb2e-900f9767c029",
   "metadata": {},
   "source": [
    "## Test untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e17f49-bfc5-43c1-b1cb-59f5bde7f70e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m#predictions = torch.argmax(logits)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mexample_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m, in \u001b[0;36mexample_predictions\u001b[0;34m(dataset, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m      3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#predictions = torch.argmax(logits)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:883\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    881\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 883\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    893\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:695\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    693\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 695\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    698\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:110\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    112\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# isues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Development/personal/steam-experiments/venv2/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "def example_predictions(dataset, model):\n",
    "    for text in dataset:\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "        logits = model(inputs).logits\n",
    "        #predictions = torch.argmax(logits)\n",
    "    \n",
    "        print(f'{logits.tolist()} = {text}')\n",
    "example_predictions(tokenized_dataset['dev']['text'][:10], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ea400f1-0fe3-4366-a27a-bb6aa0041a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01052621565759182 | 0.08921568627450979 = Good story but a little short. Took me 1h30 to finish the game, without skipping the cut scenes.\n",
      "You play a detective called upon to investigate the mysterious disappearance of a young orphan.\n",
      "The manager of the orphanage explains that since the boy disappeared, the place became hunted. Why, because of dark magic.\n",
      "You go on a little journey in the orphanage, exploring the few rooms available, looking for clues on the boys whereabouts and who did this.\n",
      "I like the Goal list they incorporated in the game. Each time you accomplish a goal, they grey it out and when you've finished all the goals for the section and you need to head out, they establish new goals. You don't have to accomplish them in order, you just need to do them all to advance in the story line.\n",
      "The hidden objects games are few, but with a little twist to them, the red objects in your list are hidden, you have to find them or accomplish an act to reveal them. Pretty fun.\n",
      "You also have puzzle, which are fun and not to difficult.\n",
      "Over all, liked the game a lot and recommend it, if you don't mind it being a little short.\n",
      "0.017141327261924744 | 0.011764705882352941 = - - - - implants are too expensive, its impossible to do good builds, implants should be\n",
      "unlocked account wide\n",
      "- - - a lot of hackers ( /report doesnt work because Daybreak doesnt care)\n",
      "- - - no hack protection\n",
      "- - never play on Double XP weekends - hackers are doubled too\n",
      "- sometimes zerg game, vehicle spam\n",
      "- short TTK\n",
      "- shadowing\n",
      "- bugs\n",
      "- bad fps (not optimized game)\n",
      "- unbalanced factions / weapons / population\n",
      "- a lot of grind\n",
      "- mines everywhere\n",
      "- faked ingame statistics\n",
      "+ teamplay = more fun\n",
      "+ very big maps\n",
      "+ good skins\n",
      "+ NO p2w\n",
      "+ base building\n",
      "UPDATE: very good patches, new dev team, new company, BUT still full of hackers....\n",
      "0.002746188547462225 | 0.0 = eh idk i just like it\n",
      "0.00299467658624053 | 0.0 = Smooth movement in game, graphically captivating, and a campaign that is interesting. Titanfall 2 is one of the better unique first person shooters out there. Along with having one of the most entertaining campaigns, Titanfall 2 has the first-person shooter/Mech-warrior multiplayer combination done perfectly.\n",
      "0.022965282201766968 | 0.0 = What you see in the screenshots is exactly what you get: A single 4x4 grid with randomized pairs, repeated for (supposedly, I did not have the patience) 80 stages in total. Your score depends on how quickly you complete them. There's no penalty for time out or mistakes, other than a potentially negative score. Each of these series entries vary only by a couple of sprites, resulting in barely distinguishable clones.\n",
      "Unlike its earlier installments, this one did not evade the restricted status and achievement limitations, so it will not count for library totals or completed games on your profile. So really, there's no actual benefit for owning it.\n",
      "These games show up regularly in gleam giveaways and other \"like, follow, subscribe\" promos, as well as cheap keyshops outside of Steam. If you insist on buying it here, you'll overpay for an easy, invisible achievement completion. Consider that Valve has wiped the platform of similar games for lesser offenses, so if QC ever gets around to inspecting these, your investment could be for nothing.\n",
      ": 1 min to 100%. Since it only has one achievement, it's quick and painless without any freezing seen in the 5K total games.\n",
      "0.0016652941703796387 | 0.0 = good\n",
      "0.002466634614393115 | 0.0 = it may be 11 years old BUT ITS STILL DAMN GOOD\n",
      "0.0018645296804606915 | 0.0 = Interesting story and good map design.\n",
      "0.013248652219772339 | 0.047058823529411764 = It's Mario Party but you get to beat the crap out of each other in the process, what's not to love.\n",
      "0.0030752005986869335 | 0.0 = This is great for theme hospital fans. all the maddness with all the fun.\n",
      "Only issue i have is the multiplayer bit. I only know one other person playing so i can not complete the challenges.\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "def example_predictions(dataset, model):\n",
    "    for text, label in zip(dataset['text'], dataset['label']):\n",
    "        \n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\").to('cuda')\n",
    "        logits = model(inputs).logits\n",
    "        # predictions = torch.max(logits, 1).indices\n",
    "    \n",
    "        print(f'{logits[0][0]} | {label} = {text}')\n",
    "example_predictions(tokenized_dataset['dev'][:10], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f79d477f-8e4b-4260-9f03-2d3732130e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 = I totally agree the best bit of the sims making dream homes, but really needs the ability to sell and make a profit so you can buy more land and build your housing empire. Love the designs and the possibilities for the game\n",
      "1 = Banger game cheap when on sale comes with a lot of dlc! Start the exe from the main folder and it won't crash because \"ran out of memory\" as much and enjoy pasting all those codes for the keys. I think 7 hours out of my 12 is just pasting codes.\n",
      "1 = Too much random ♥♥♥♥♥♥♥♥.\n",
      "1 = Story - 8\n",
      "Visuals - 9\n",
      "Audio - 9\n",
      "Gameplay - 8\n",
      "Length - 6\n",
      "Replayability - 7\n",
      "Value base $ - 6\n",
      "Value sale ($3.74) - 8\n",
      "Overall - 8\n",
      "1 = This game is awesome. Play it.\n",
      "1 = Great story, a visual novel walking simulator which is fueled by the modern non-organic extraterrestrial travelling theories. Better than most movies i guess..\n",
      "Oh! It ran well, with full details with my 7 years old 1070GTX card, exhibiting me a visually stunning red planet\n",
      "1 = amazing game the artstyle is creepy the controls are awesome and basically everything is cool\n",
      "1 = Some really tedious game mechanics (even by RGG standards - e.g. endless tailing missions, fiddling with keys, etc.) with mostly below average side quests. However, the main story and the accompanying soundtrack is excellent and more than makes up for these flaws. This would probably be an even better game overall if it wasn't chained back by the usual RGG elements which did little to improve the quality of the game anyway.\n",
      "1 = I really enjoy this game. If you want a FPS that takes elements of CoD and CSGO, and puts them into a F2P game, this is worth checking out. Might not be perfect, but I mean c'mon it's still early access. Play it, and take it for what it is. It is still a developing game. It has great potential. It runs well on my old toaster laptop, has fun game modes, and balanced guns, cool maps, so I vote yes for Black Sqaud, despite its minor flaws.\n",
      "1 = > Got the game out of pure curiosity\n",
      "> Hmm, the artwork and soundtrack are pretty nice\n",
      "> Get outside for the first time\n",
      "> HOLY ♥♥♥♥♥ IT'S SO MESMERIZING AND SORROWFUL AT THE SAME TIME, WTH\n",
      "> Yeah, Mili did the soundtrack, so that's why\n",
      "> Tbh, the combat and exploration is not that varied, huh\n",
      "> Regret saying so cuz later, the map is so large and overwhelming that it made me feel helpless at times\n",
      "> The combat got so much better after each boss fight. Srsly, progressing in this game feels so satisfying.\n",
      "> The story and the lore... man... it adds so much to the game. I just read the some left behind notes and im sad af rn.\n",
      "> At some point, reach Verboten Domain\n",
      "> Feel the dread and fear constantly\n",
      "> Reach the Abyss\n",
      "> SH** MY PANTS WHILE SUFFOCATING IN THE GAS CHAMBER\n",
      "> Reach final boss\n",
      "> Cry\n",
      "10/10 would recommend playing it all again\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "def example_predictions(dataset, model):\n",
    "    for text in dataset:\n",
    "        inputs = tokenizer.encode(text, return_tensors=\"pt\").to('cuda')\n",
    "        logits = model(inputs).logits\n",
    "        predictions = torch.max(logits, 1).indices\n",
    "    \n",
    "        print(f'{predictions.tolist()[0]} = {text}')\n",
    "example_predictions(tokenized_dataset['dev']['text'][:10], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb54cb44-cd24-486a-bf1b-cab60125e745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fead73-d4d4-4ee8-bd0c-a0e57e2082b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

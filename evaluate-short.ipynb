{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb44827-a885-4e93-8517-94e4244f6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "manual_seed = 23\n",
    "\n",
    "np.random.seed(manual_seed)\n",
    "pl.set_random_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850681a-2cce-495d-9d72-261dd7609ec6",
   "metadata": {},
   "source": [
    "# Evaluating - transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3abe3aa-621d-4e2c-a1ca-b985e7613071",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/500k_50k'\n",
    "recommend_models = {\n",
    "    'distilbert': 'models/backup/steam-classification-distilbert500k/checkpoint-15625',\n",
    "    'roberta': 'models/backup/steam-classification-roberta500k/checkpoint-31250',\n",
    "}\n",
    "funny_models = {\n",
    "    'distilbert': 'models/steam-classification-distilbert500k-funny/checkpoint-14067',\n",
    "    'roberta': 'models/backup/steam-classification-roberta500k-funny/checkpoint-31250',\n",
    "}\n",
    "helpful_models = {\n",
    "    'distilbert': 'models/steam-classification-distilbert500k-helpful/checkpoint-15625',\n",
    "    'roberta': 'models/steam-classification-roberta500k-helpful/checkpoint-31250',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093adb68-5bbe-444f-bb7d-180762d63cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(column):\n",
    "    '''\n",
    "    Selects a proper column. They could be `recommended`, `found_funny` or `found_helpful`.\n",
    "    '''\n",
    "    df_test = pl.read_parquet(filename + '_test.parquet')\n",
    "    df_test = df_test.select(['review_text', column]).rename({'review_text': 'text', column: 'label'})\n",
    "    dataset = DatasetDict({'test': Dataset(df_test.to_arrow())})\n",
    "    \n",
    "    return df_test, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66cdf03-be6c-40e4-8e4d-3b1e77e77a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_classification_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)['accuracy']}\n",
    "    # return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e3aa081-b548-4500-9b24-1df8553a7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "def compute_regression_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    mse = mean_squared_error(labels, predictions)\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "    \n",
    "    return {\"mse\": mse, \"mae\": mae, \"r2\": r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a244143-77d9-4ba1-98f5-eeacc80a8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model_path, df_test, dataset, compute_metrics):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    def tokenize_function(examples):\n",
    "        text = examples[\"text\"]\n",
    "        # it is possible to return tensors in pytorch, but then you need to pad everything which is inconvenient because it is better to do in collator\n",
    "        return tokenizer(text, truncation=True, return_tensors=\"np\", max_length=128)\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    return trainer.predict(test_dataset=tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "354070b7-a276-4ff4-915c-1a103f468fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_regression_evaluations(models, column):\n",
    "    results = {'model_name': [], 'mse': [], 'mae': [], 'r2': []}\n",
    "    df, dataset = load_data(column)\n",
    "    for model_name, model_path in models.items():\n",
    "        predictions, _, metrics = evaluate(model_path, df, dataset, compute_regression_metrics)\n",
    "        df = df.with_columns(\n",
    "            pl.lit(predictions.reshape(-1)).alias(model_name)\n",
    "        )\n",
    "        results['model_name'].append(model_name)\n",
    "        results['mse'].append(metrics['test_mse'])\n",
    "        results['mae'].append(metrics['test_mae'])\n",
    "        results['r2'].append(metrics['test_r2'])\n",
    "    \n",
    "    # what if all predictions are 0\n",
    "    metrics = compute_regression_metrics((np.zeros(len(df['label'])), df['label'].to_numpy()))\n",
    "    results['model_name'].append('baseline')\n",
    "    results['mse'].append(metrics['mse'])\n",
    "    results['mae'].append(metrics['mae'])\n",
    "    results['r2'].append(metrics['r2'])\n",
    "    \n",
    "    return pl.DataFrame(results), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43700d38-ee76-4a29-856c-33af76e4aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_classification_evaluations(models, column):\n",
    "    results = {'model_name': [], 'accuracy': []}\n",
    "    df, dataset = load_data(column)\n",
    "    for model_name, model_path in models.items():\n",
    "        predictions, _, metrics = evaluate(model_path, df, dataset, compute_classification_metrics)\n",
    "        df = df.with_columns(\n",
    "            pl.lit(np.argmax(predictions, axis=1)).alias(model_name)\n",
    "        )\n",
    "        results['model_name'].append(model_name)\n",
    "        results['accuracy'].append(metrics['test_accuracy'])\n",
    "    \n",
    "    # what if all predictions are 0\n",
    "    metrics = compute_classification_metrics((np.concatenate((np.zeros((50000, 1)), np.ones((50000, 1))), axis=1), df['label'].to_numpy()))\n",
    "    results['model_name'].append('baseline')\n",
    "    results['accuracy'].append(metrics['accuracy'])\n",
    "    \n",
    "    return pl.DataFrame(results), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91f2f570-4483-4034-aa32-4bc3410b8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd181ff0c55044908ea4d44ba066d399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e04265b05f4db18030b36c574c7314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_recommended_results, df_recommended_details = collect_classification_evaluations(recommend_models, 'recommended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec087ee7-3ab7-4a7c-86be-2a6373141742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3d201c10cc493f9796147e54f98374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d5698d59c74931b6695dceb8e229b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_funny_results, df_funny_details = collect_regression_evaluations(funny_models, 'found_funny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1973413f-8be4-47ac-89bd-8c5101ef67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4611e5279249748b34deca05ffc284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e46cc72df64e178726ddec2ebb34b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_helpful_results, df_helpful_details = collect_regression_evaluations(helpful_models, 'found_helpful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb30b39f-14af-46c8-ab58-4f43d8316e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommended_results.write_csv('evaluations/recommend_metrics.csv')\n",
    "df_recommended_details.write_csv('evaluations/recommend_details.csv')\n",
    "df_funny_results.write_csv('evaluations/funny_metrics.csv')\n",
    "df_funny_details.with_columns(pl.col([\"label\", \"distilbert\", \"roberta\"]).round(3)).write_csv('evaluations/funny_details.csv')\n",
    "df_helpful_results.write_csv('evaluations/helpful_metrics.csv')\n",
    "df_helpful_details.with_columns(pl.col([\"label\", \"distilbert\", \"roberta\"]).round(3)).write_csv('evaluations/helpful_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93a12ab1-d6ad-48fb-b923-44cc7b825169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>accuracy</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distilbert&quot;</td><td>0.95132</td></tr><tr><td>&quot;roberta&quot;</td><td>0.9598</td></tr><tr><td>&quot;baseline&quot;</td><td>0.87588</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────┬──────────┐\n",
       "│ model_name ┆ accuracy │\n",
       "│ ---        ┆ ---      │\n",
       "│ str        ┆ f64      │\n",
       "╞════════════╪══════════╡\n",
       "│ distilbert ┆ 0.95132  │\n",
       "│ roberta    ┆ 0.9598   │\n",
       "│ baseline   ┆ 0.87588  │\n",
       "└────────────┴──────────┘"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recommended_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9ad15d-8281-46a7-ae99-e84a881e6e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>mse</th><th>mae</th><th>r2</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distilbert&quot;</td><td>0.002015</td><td>0.010775</td><td>0.022518</td></tr><tr><td>&quot;roberta&quot;</td><td>0.002008</td><td>0.008409</td><td>0.025824</td></tr><tr><td>&quot;baseline&quot;</td><td>0.002098</td><td>0.006068</td><td>-0.017862</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌────────────┬──────────┬──────────┬───────────┐\n",
       "│ model_name ┆ mse      ┆ mae      ┆ r2        │\n",
       "│ ---        ┆ ---      ┆ ---      ┆ ---       │\n",
       "│ str        ┆ f64      ┆ f64      ┆ f64       │\n",
       "╞════════════╪══════════╪══════════╪═══════════╡\n",
       "│ distilbert ┆ 0.002015 ┆ 0.010775 ┆ 0.022518  │\n",
       "│ roberta    ┆ 0.002008 ┆ 0.008409 ┆ 0.025824  │\n",
       "│ baseline   ┆ 0.002098 ┆ 0.006068 ┆ -0.017862 │\n",
       "└────────────┴──────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_funny_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d5207a-2325-4ccf-84cd-7d1c39fcd71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>mse</th><th>mae</th><th>r2</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distilbert&quot;</td><td>0.002339</td><td>0.013148</td><td>0.04566</td></tr><tr><td>&quot;roberta&quot;</td><td>0.00232</td><td>0.013807</td><td>0.053243</td></tr><tr><td>&quot;baseline&quot;</td><td>0.002532</td><td>0.009021</td><td>-0.033202</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 4)\n",
       "┌────────────┬──────────┬──────────┬───────────┐\n",
       "│ model_name ┆ mse      ┆ mae      ┆ r2        │\n",
       "│ ---        ┆ ---      ┆ ---      ┆ ---       │\n",
       "│ str        ┆ f64      ┆ f64      ┆ f64       │\n",
       "╞════════════╪══════════╪══════════╪═══════════╡\n",
       "│ distilbert ┆ 0.002339 ┆ 0.013148 ┆ 0.04566   │\n",
       "│ roberta    ┆ 0.00232  ┆ 0.013807 ┆ 0.053243  │\n",
       "│ baseline   ┆ 0.002532 ┆ 0.009021 ┆ -0.033202 │\n",
       "└────────────┴──────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_helpful_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "419ff3db-d790-4adb-88b6-54e7a9ab47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funny_details.filter((pl.col('text').str.len_chars() > 20) & (pl.col('text').str.len_chars() < 50)).sort('label', descending=True).write_csv('evaluations/funny_details_readable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35fc312c-649b-4ebb-a3cf-c82dbb9320cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_helpful_details.filter((pl.col('text').str.len_chars() > 20) & (pl.col('text').str.len_chars() < 50)).sort('label', descending=True).write_csv('evaluations/helpful_details_readable.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hidden-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import string\n",
    "manual_seed = 23\n",
    "\n",
    "np.random.seed(manual_seed)\n",
    "pl.set_random_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab5b78-a47f-4b45-899e-613326da50d9",
   "metadata": {},
   "source": [
    "# Reading database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e93cf99-5fdf-42ca-b6b9-f34d225ce816",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'dbs/db.sqlite3'\n",
    "connection_string = 'sqlite://' + db_path\n",
    "df = pl.read_database_uri(\n",
    "    '''SELECT product_id, text AS review_text, recommended, found_helpful, found_funny \n",
    "    FROM review LEFT JOIN product ON product_id = product.id''',\n",
    "    connection_string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613bf077-212b-42ad-9065-1d03b727ee52",
   "metadata": {},
   "source": [
    "# Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ea6b4f-55e5-4a3c-8626-9283ad14d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to integers\n",
    "df = df.with_columns(\n",
    "    # cast features to minimal viable types\n",
    "    pl.col(\"found_funny\").cast(pl.UInt16, strict=False).fill_null(strategy=\"zero\"),\n",
    "    pl.col(\"found_helpful\").cast(pl.UInt16, strict=False).fill_null(strategy=\"zero\"),\n",
    "    pl.col(\"recommended\").cast(pl.Int8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cdb5a25-6ac0-4815-a161-6711d8b94ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "# filter out reviews that don't contain any letters.\n",
    "df = df.filter(pl.col('review_text').str.contains_any(list(string.ascii_lowercase) + list(string.ascii_uppercase)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6425f-e7e3-42dc-ac61-3ef4b94ca35e",
   "metadata": {},
   "source": [
    "# Regression Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4492cb1a-14b5-4dd0-8031-463138029082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_column(df: pl.DataFrame, column_name: str, quantile: float=0.999, new_column_name: str=None) -> (pl.DataFrame, float):\n",
    "    \"\"\"\n",
    "    When a value in a specified column falls outside the specified quantile, make it equal to the largest value in the specified quantile.\n",
    "    This is used to clip big outliers.\n",
    "    \"\"\"\n",
    "    if new_column_name is None:\n",
    "        new_column_name = column_name\n",
    "    cutoff_value = df.select(column_name).quantile(0.999)\n",
    "    return pl.when(pl.col(column_name) > cutoff_value).then(cutoff_value).otherwise(pl.col(column_name)).alias(new_column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef3d595c-a3be-4d7e-802b-0e50c6171d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create normalized metrics\n",
    "df = df.with_columns(\n",
    "    clip_column(df, 'found_funny', new_column_name='found_funny_cutoff'),\n",
    "    clip_column(df, 'found_helpful', new_column_name='found_helpful_cutoff')\n",
    ")\n",
    "df = df.with_columns(\n",
    "    (\n",
    "        (\n",
    "            (pl.col(\"found_funny_cutoff\") / pl.col(\"found_funny_cutoff\").max()) + \n",
    "            (pl.col(\"found_funny_cutoff\") / pl.col(\"found_funny_cutoff\").max()).over(\"product_id\")\n",
    "        ) / 2).fill_nan(0.0).alias(\"found_funny\"),\n",
    "    (\n",
    "        (\n",
    "            (pl.col(\"found_helpful_cutoff\") / pl.col(\"found_helpful_cutoff\").max()) + \n",
    "            (pl.col(\"found_helpful_cutoff\") / pl.col(\"found_helpful_cutoff\").max()).over(\"product_id\")\n",
    "        ) / 2).fill_nan(0.0).alias(\"found_helpful\")\n",
    ")\n",
    "df = df.drop([\"found_funny_cutoff\", \"found_helpful_cutoff\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f0b96-5e73-45fc-84e8-f29a3f74d710",
   "metadata": {},
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d4086-b622-415d-a622-5e92803869b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train test dev\n",
    "df_split = df.select(\"product_id\").unique(\"product_id\").sort(\"product_id\")\n",
    "df_split = df_split.with_columns(\n",
    "    pl.lit(np.random.rand(df_split.height)).alias(\"split\")\n",
    ")\n",
    "df_split = df_split.with_columns(\n",
    "    pl.when(pl.col(\"split\") < 0.8).then(pl.lit(\"train\"))\n",
    "        .otherwise(pl.when(pl.col(\"split\") < 0.9).then(pl.lit(\"test\"))\n",
    "        .otherwise(pl.lit(\"dev\"))).alias(\"split\")\n",
    ")\n",
    "df_dict = df.join(df_split, on=\"product_id\", how=\"left\").partition_by(\"split\", as_dict=True, include_key=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aae524d-684e-4e5a-a62d-d10051aa26a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_parquet(df_dict, filename):\n",
    "    df_dict[(\"train\",)].write_parquet(filename + '_train.parquet')\n",
    "    df_dict[(\"test\",)].write_parquet(filename + '_test.parquet')\n",
    "    df_dict[(\"dev\",)].write_parquet(filename + '_dev.parquet')\n",
    "\n",
    "write_parquet(df_dict, \"data/complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371db6ac-7a0d-4cf5-bcaa-c20b8e6f4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict_500k = {}\n",
    "df_dict_500k[(\"train\",)] = df_dict[(\"train\",)].sample(500000, seed=manual_seed, shuffle=True)\n",
    "df_dict_500k[(\"test\",)] = df_dict[(\"test\",)].sample(50000, seed=manual_seed, shuffle=True)\n",
    "df_dict_500k[(\"dev\",)] = df_dict[(\"dev\",)].sample(50000, seed=manual_seed, shuffle=True)\n",
    "\n",
    "write_parquet(df_dict_500k, \"data/500k_50k\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
